## Creazione di rete virtuale (VEDERE PIU AVANTI)

> Attenzione !!!
> 
> Questa procedura Ã¨ in fase di test. Solo al termine positivo del test verrÃ  
> cancellata questa annotazione. 
> 
> I passi seguenti sono da ritenersi solo indicativi.



Il primo passo da fare Ã¨ assicurarsi che il sistema SDN (Software Development Network) sia attivo.

Per ogni nodo del cluster, accertarsi che al fondo del file `/etc/network/interfaces` ci sia attiva la seguente linea:

```text
source /etc/network/interfaces.d/*
```

Poi per ogni nodo occorre installare il pacchetto `dnsmasq` per attivare il servizio DHCP

```bash
apt update
apt install dnsmasq
# disable default instance
systemctl disable --now dnsmasq
```

Inoltre installare anche il pacchetto `FRRouting` necessario per configurazioni avanzate di SDN

```bash
apt install frr-pythontools
```

A questo punto Ã¨ consigliabile effettuare un _reboot_ dei nodi.



Perfetto! Ecco una guida passo-passo per configurare Zone e VNet in Proxmox VE 8.1+ per far comunicare container LXC su nodi diversi, sfruttando la modalitÃ  overlay (quindi rete virtuale distribuita).

â¸»

ðŸ§° Requisiti iniziali
	â€¢	Proxmox VE 8.1 o superiore
	â€¢	Due nodi giÃ  in cluster
	â€¢	LXC abilitati
	â€¢	Pacchetti aggiornati:

apt update && apt full-upgrade



â¸»

ðŸ› ï¸ 1. Abilita il supporto per vnets e zones

Verifica che la gestione del networking cluster sia attiva:

pveversion | grep pve-manager

Deve essere almeno 8.1.

Puoi anche abilitare lâ€™interfaccia da Web GUI:
	â€¢	Vai su Datacenter â†’ Permissions â†’ User Permissions
	â€¢	Assegna il ruolo PVEAdmin al tuo utente se serve, per accedere alla sezione VNet/Zone.

â¸»

ðŸŒ 2. Crea una Zone
	â€¢	Vai su Datacenter â†’ Zones 
	â€¢	Clicca su â€œAddâ€ -> VXLAN
	â€¢	ID: default (o un nome a tua scelta)
	â€¢	Description: es. Zona LAN virtuale
	â€¢	Nodes: seleziona entrambi i tuoi nodi (pve1, pve2)
	â€¢	Peer Address List: 100.x.y.z 100.a.b.c
	â€¢	Lascia le altre opzioni di default



Clicca Create.

â¸»

ðŸ”Œ 3. Crea una VNet in modalitÃ  Overlay
	â€¢	Vai su Datacenter â†’ VNets
	â€¢	Clicca â€œAddâ€
	â€¢	ID: lan-vnet
	â€¢	Zone: default
	â€¢	CIDR: 10.42.0.0/24 (esempio)
	â€¢	Gateway: 10.42.0.1
	â€¢	Mode: overlay âœ…
	â€¢	DNS: opzionale (puoi mettere 1.1.1.1 o lasciare vuoto)
	â€¢	DHCP Range: 10.42.0.100 - 10.42.0.200 (se vuoi usare il DHCP)
	â€¢	MTU: lascialo vuoto o metti 1400
	â€¢	Nodes: entrambi i nodi

Clicca Create.

â¸»

ðŸ§± 4. (Opzionale) Abilita Firewall e ACL

Vai su:
	â€¢	Datacenter â†’ Firewall
	â€¢	Imposta Enable = Yes
	â€¢	Puoi poi gestire regole per zona o container

â¸»

ðŸ§ª 5. Crea due LXC connessi alla VNet

Su pve1:
	â€¢	Vai su Create CT
	â€¢	Nella scheda Network:
	â€¢	Aggiungi interfaccia
	â€¢	In Bridge, seleziona la tua VNet (lan-vnet@default)
	â€¢	Imposta IP statico (es: 10.42.0.10/24) oppure lascia vuoto per usare DHCP

Su pve2:
	â€¢	Stessa cosa, con IP diverso (es: 10.42.0.11/24)

â¸»

ðŸ§ª 6. Test di rete

Dopo lâ€™avvio dei container:

pct exec 100 ping 10.42.0.11
pct exec 101 ping 10.42.0.10

Dovresti vedere traffico attraversare i due nodi grazie al VXLAN gestito da Proxmox!

â¸»

ðŸš€ Extra: Accesso a internet da container

Se vuoi che i container abbiano anche uscita su internet:
	1.	Vai su ciascun nodo (pve1, pve2)
	2.	Abilita NAT da VNet a WAN con iptables o Proxmox Firewall:

iptables -t nat -A POSTROUTING -s 10.42.0.0/24 -o vmbr0 -j MASQUERADE



Puoi automatizzarlo con uno script o aggiungerlo a /etc/network/interfaces con post-up.

â¸»

ðŸ§¹ Consigli finali
	â€¢	Le VNet overlay usano automaticamente VXLAN su UDP, e funzionano bene anche su Tailscale!
	â€¢	Puoi avere piÃ¹ zone per isolare ambienti (es: zona â€œprodâ€, zona â€œtestâ€)
	â€¢	Funziona anche con VM, non solo LXC

â¸»

Vuoi uno script per automatizzare la parte iptables/NAT oppure uno YAML di esempio per creare container collegati alla VNet?

   
## Preparazione di una rete privata


SÃ¬, assolutamente sÃ¬!
Puoi creare una rete interna in Proxmox che:
	â€¢	dia IP privati ai container LXC in automatico tramite DHCP,
	â€¢	e faccia anche NAT per farli uscire su internet,
	â€¢	e permetta a te di fare port forwarding verso i container.

In pratica, puoi avere una mini-â€œrete casalingaâ€ virtuale dentro Proxmox.

â¸»

Come fare

Ti spiego come fare passo passo ðŸ‘‡

â¸»

1. Crea una nuova bridge (vmbr1)

> NOTA
>
> Ho effettuato la creazione dall'interfaccia Networks di Proxmox, e applicando la rete risulta attiva.
> Editando a mano il file non avviene l'attivazione in automatico.

Accedi alla tua Proxmox VM (quella su Oracle Cloud) via SSH.

Apri il file /etc/network/interfaces:

```bash
sudo nano /etc/network/interfaces
```

E aggiungi una nuova bridge chiamata vmbr1, tipo:

```text
auto vmbr1
iface vmbr1 inet static
    address 192.168.100.1/24
    bridge-ports none
    bridge-stp off
    bridge-fd 0
```

ðŸ‘‰ Qui vmbr1 ha IP 192.168.100.1 e nessuna porta fisica collegata (bridge interno).

â¸»

2. Installa un piccolo server DHCP+NAT

Ora installiamo un software che dia:
	â€¢	DHCP ai container
	â€¢	NAT verso Internet (uscita su IP pubblico)

Il piÃ¹ semplice Ã¨ dnsmasq + NAT via iptables.

Installa dnsmasq:

```bash
sudo apt update
sudo apt install dnsmasq
```


â¸»

3. Configura dnsmasq per vmbr1

Crea un file /etc/dnsmasq.d/lxc-net.conf:

```bash
sudo nano /etc/dnsmasq.d/lxc-net.conf
```

Contenuto:

```text
interface=vmbr1
bind-interfaces
dhcp-range=192.168.100.10,192.168.100.100,12h
```

	â€¢	Questo fa partire DHCP sulla vmbr1
	â€¢	Da IP .10 a .100, lease 12 ore

Poi riavvia dnsmasq:

```bash
sudo systemctl restart dnsmasq
```


â¸»

4. Abilita il NAT (per far uscire i container su internet)

Imposta il NAT con iptables:

```bash
# Abilita il forwarding di pacchetti
sudo sysctl -w net.ipv4.ip_forward=1

# Regola NAT: maschera tutto ciÃ² che esce da Internet
sudo iptables -t nat -A POSTROUTING -s 192.168.100.0/24 -o enp0s3 -j MASQUERADE
```

(Nota: sostituisci enp0s3 con il nome della tua scheda di rete pubblica, puoi vederla con ip a)

Se vuoi rendere permanente:

```bash
sudo apt install iptables-persistent
sudo netfilter-persistent save
```


â¸»

5. Configura i container LXC per usare vmbr1

Quando crei o modifichi un container:
	â€¢	Vai su Proxmox Web UI
	â€¢	Scegli il container
	â€¢	Sezione Network
	â€¢	Imposta la scheda su Bridge: vmbr1 (invece di vmbr0 o altro)
	â€¢	Metodo IP: DHCP

Risultato:
Ogni container attaccato a vmbr1 riceverÃ  automaticamente un IP 192.168.100.x ðŸŽ¯

â¸»

6. E ora il Port Forwarding?

Con questa configurazione:
	â€¢	Puoi fare come prima (iptables PREROUTING) per girare le porte dal IP pubblico della VM verso gli IP dei container.

Ad esempio:

sudo iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination 192.168.100.10:80



â¸»

Schema finale:

Internet --> Oracle VM IP Pubblico:80 --> iptables --> Container IP Privato (es. 192.168.100.10:80)

E tutti i container si gestiscono automaticamente via DHCP ðŸ”¥

â¸»



## TAILSCALE come pubblicazione della sottorete

SÃ¬, confermo! ðŸ”¥
Con Tailscale puoi pubblicare lâ€™intera sottorete vmbr1, cosÃ¬ che tu possa raggiungere tutti i container LXC via Tailscale, senza esporre nulla su internet.

Questa funzione si chiama Subnet Router.

â¸»

Cosa significa â€œSubnet Routerâ€?
	â€¢	La macchina Proxmox (dove hai Tailscale installato)
âž” pubblicherÃ  verso la VPN Tailscale la rete 192.168.100.0/24 (la rete dei tuoi container su vmbr1).
	â€¢	Dal tuo computer, se sei collegato a Tailscale, potrai raggiungere direttamente tutti i container LXC.

â¸»

Come configurarlo

1. Abilita il â€œforwardingâ€ IP su Proxmox

Prima di tutto, assicurati che il tuo sistema permetta di inoltrare pacchetti di rete:

sudo sysctl -w net.ipv4.ip_forward=1

Per renderlo permanente (dopo un reboot), aggiungilo in /etc/sysctl.conf:

echo "net.ipv4.ip_forward=1" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p



â¸»

2. Rilancia Tailscale con il parametro --advertise-routes

Ora, sul nodo Proxmox dove gira Tailscale, devi pubblicare la rete:

sudo tailscale up --advertise-routes=192.168.100.0/24

(aggiungi anche --accept-routes=true se vuoi subito ricevere eventuali subnet da altri)

â¸»

3. Approva il subnet router nella dashboard di Tailscale

Vai sulla dashboard Tailscale:

https://login.tailscale.com/admin/machines

	â€¢	Cerca la tua macchina Proxmox.
	â€¢	Vedrai una notifica â€œSubnet routes pendingâ€.
	â€¢	Clicca Approve per il route 192.168.100.0/24.

âœ… Ora il route Ã¨ visibile a tutti i device Tailscale autorizzati.

â¸»

4. Assicurati che il client Tailscale possa usare le rotte

Se stai usando un client Tailscale:
	â€¢	Su desktop (Windows, macOS, Linux) va tutto automatico.
	â€¢	Su Mobile (iOS/Android) devi abilitare â€œUse exit node / Allow remote subnetsâ€ nelle impostazioni Tailscale.

â¸»

ðŸš€ Risultato finale

Ora puoi da qualsiasi dispositivo connesso alla tua rete Tailscale:
	â€¢	pingare gli LXC tipo ping 192.168.100.10
	â€¢	raggiungerli via browser su http://192.168.100.10
	â€¢	SSH direttamente se hai server SSH sui container.

â¸»

Schema visivo della rete

[ Tu su Tailscale ] ---> [ Proxmox ] ---> [ vmbr1 ] ---> [ LXC 192.168.100.x ]



â¸»

Riepilogo

Step	Cosa fai
1	Abiliti IP forwarding
2	Rilanci Tailscale con --advertise-routes=192.168.100.0/24
3	Approvi route da dashboard Tailscale
4	Usi Tailscale normalmente per raggiungere i container

